{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the file that we are trying to train on is massive,\n",
    "# we must program it so that it randomly generates images\n",
    "# across class in  a lazy manner. \n",
    "\n",
    "\n",
    "# Our strategy is to train on N classes and for create\n",
    "# minibatches of size batch_size.\n",
    "import tarfile\n",
    "import random\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "class LazyRandomMinibatchGenerator:\n",
    "    def __init__(self, tar_path, N):\n",
    "        \"\"\"\n",
    "        :param tar_path: Path to the .tar.gz file containing images.\n",
    "        :param N: Number of classes to sample from per minibatch.\n",
    "        \"\"\"\n",
    "        self.tar_path = tar_path\n",
    "        self.N = N\n",
    "        \n",
    "        # class_name -> deque of file paths\n",
    "        self.images_by_class = defaultdict(deque)\n",
    "        \n",
    "        # Keep the tarfile open and track our current read position\n",
    "        self.tar = tarfile.open(self.tar_path, \"r:gz\")\n",
    "        \n",
    "        self.end_of_archive = False  # True when we've read the entire tar\n",
    "        self.all_discovered_classes = set()  # Classes we've found so far\n",
    "        self.exhausted_classes = set()  # Classes that ran out of images\n",
    "        \n",
    "        # Internal generator over tar members (for lazy reading)\n",
    "        self._tar_iter = None\n",
    "\n",
    "    @property\n",
    "    def tar_iterator(self):\n",
    "        \"\"\"\n",
    "        A generator that yields members from the tarfile, \n",
    "        preserving our read position.\n",
    "        \"\"\"\n",
    "        if self._tar_iter is None:\n",
    "            self._tar_iter = (m for m in self.tar)\n",
    "        return self._tar_iter\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the tarfile (once you're completely done generating).\"\"\"\n",
    "        self.tar.close()\n",
    "\n",
    "    def _read_until_we_have_enough_classes(self, needed_classes):\n",
    "        \"\"\"\n",
    "        Read from the tar until we have at least `needed_classes` \n",
    "        classes discovered or we reach the end of the archive.\n",
    "        \"\"\"\n",
    "        if self.end_of_archive:\n",
    "            return\n",
    "        \n",
    "        while len(self.all_discovered_classes) < needed_classes:\n",
    "            try:\n",
    "                member = next(self.tar_iterator)\n",
    "            except StopIteration:\n",
    "                self.end_of_archive = True\n",
    "                break\n",
    "            \n",
    "            parts = member.name.split(\"/\")\n",
    "            # We expect something like: imagenet21k_resized/imagenet21k_small_classes/<class>/<filename>\n",
    "            if len(parts) > 2 and member.isfile():\n",
    "                class_name = parts[2]\n",
    "                self.all_discovered_classes.add(class_name)\n",
    "                self.images_by_class[class_name].append(member.name)\n",
    "\n",
    "    def _shuffle_exhausted_classes(self):\n",
    "        \"\"\"\n",
    "        If all discovered classes are exhausted, re-shuffle their deques \n",
    "        so they can be reused in future batches.\n",
    "        \"\"\"\n",
    "        if len(self.exhausted_classes) == len(self.all_discovered_classes):\n",
    "            # All known classes are exhausted; reshuffle each class's deque\n",
    "            for cls in self.all_discovered_classes:\n",
    "                file_list = list(self.images_by_class[cls])\n",
    "                random.shuffle(file_list)\n",
    "                self.images_by_class[cls] = deque(file_list)\n",
    "            \n",
    "            self.exhausted_classes.clear()\n",
    "\n",
    "    def generate_minibatch(self, batch_size):\n",
    "        \"\"\"\n",
    "        Generate a minibatch of size `batch_size`, selecting from up to N distinct classes.\n",
    "        The images from these classes are mixed (round-robin or random) so that \n",
    "        multiple classes appear in the same minibatch.\n",
    "        \"\"\"\n",
    "        # 1) Ensure we have discovered at least N non-empty classes (if possible)\n",
    "        non_empty_classes = [c for c in self.all_discovered_classes \n",
    "                             if self.images_by_class[c]]\n",
    "\n",
    "        # If we don't have enough classes, read more from the tar\n",
    "        while len(non_empty_classes) < self.N and not self.end_of_archive:\n",
    "            needed = max(self.N, len(self.all_discovered_classes) + 10)\n",
    "            self._read_until_we_have_enough_classes(needed)\n",
    "            non_empty_classes = [c for c in self.all_discovered_classes\n",
    "                                 if self.images_by_class[c]]\n",
    "\n",
    "        # Pick up to N random classes from the non-empty ones\n",
    "        if len(non_empty_classes) == 0:\n",
    "            # No data at all\n",
    "            return []\n",
    "        elif len(non_empty_classes) <= self.N:\n",
    "            chosen_classes = non_empty_classes\n",
    "        else:\n",
    "            chosen_classes = random.sample(non_empty_classes, self.N)\n",
    "\n",
    "        # 2) Collect images from these chosen classes in a round-robin/random manner\n",
    "        minibatch = []\n",
    "        while len(minibatch) < batch_size and chosen_classes:\n",
    "            # We'll sample from classes in random order each iteration\n",
    "            random_order = random.sample(chosen_classes, len(chosen_classes))\n",
    "            \n",
    "            for cls in random_order:\n",
    "                if len(minibatch) >= batch_size:\n",
    "                    break  # Stop if we have enough images\n",
    "                if self.images_by_class[cls]:\n",
    "                    minibatch.append(self.images_by_class[cls].popleft())\n",
    "                    # If the class is now empty, mark it as exhausted\n",
    "                    if not self.images_by_class[cls]:\n",
    "                        self.exhausted_classes.add(cls)\n",
    "                        chosen_classes.remove(cls)\n",
    "                else:\n",
    "                    self.exhausted_classes.add(cls)\n",
    "                    chosen_classes.remove(cls)\n",
    "        \n",
    "        # 3) If all discovered classes are exhausted, reshuffle them\n",
    "        self._shuffle_exhausted_classes()\n",
    "\n",
    "        return minibatch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'else' statement on line 21 (2748051627.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 22\u001b[0;36m\u001b[0m\n\u001b[0;31m    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'else' statement on line 21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameters\n",
    "# -------------------------\n",
    "data_dir = '/path/to/imagenet/'\n",
    "batch_size = 256\n",
    "num_workers = 8\n",
    "num_epochs = 90\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "print_freq = 50  # Steps between printing training status\n",
    "\n",
    "# -------------------------\n",
    "# Device configuration\n",
    "# -------------------------\n",
    "if torch.mps.is_available():\n",
    "    device_setting = 'mps'\n",
    "elif torch.cuda.is_available():\n",
    "    device_setting = 'cude'\n",
    "else:\n",
    "    device_setting ='cpu'\n",
    "device = torch.device(device_setting)\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "    # -------------------------\n",
    "    # Transforms and Datasets\n",
    "    # -------------------------\n",
    "    # Official ImageNet stats; can be used for normalization\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "    \n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    \n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    \n",
    "    train_dataset = torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, 'train'), transform=train_transforms\n",
    "    )\n",
    "    val_dataset = torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, 'val'), transform=val_transforms\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # -------------------------\n",
    "    # Model, Loss, Optimizer\n",
    "    # -------------------------\n",
    "    # Using a standard ResNet-18 from torchvision\n",
    "    model = models.resnet18(pretrained=False)  # set pretrained=True to fine-tune\n",
    "    # Change the final layer to match the 1000-class ImageNet\n",
    "    # (not necessary if using the original ResNet-18 from torchvision, which outputs 1000 classes)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 1000)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                          momentum=momentum, weight_decay=weight_decay)\n",
    "    \n",
    "    # Optional: learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "    # -------------------------\n",
    "    # Training & Validation Loops\n",
    "    # -------------------------\n",
    "    for epoch in range(num_epochs):\n",
    "        # ---- Train ----\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute training statistics\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            if (i+1) % print_freq == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "                      f\"Step [{i+1}/{len(train_loader)}], \"\n",
    "                      f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Training Loss: {epoch_loss:.4f}, Accuracy: {100.0*epoch_acc:.2f}%\")\n",
    "        \n",
    "        # Step the scheduler (if you are using one)\n",
    "        scheduler.step()\n",
    "\n",
    "        # ---- Validate ----\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        \n",
    "        val_loss /= val_total\n",
    "        val_accuracy = val_correct / val_total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Validation Loss: {val_loss:.4f}, Accuracy: {100.0*val_accuracy:.2f}%\")\n",
    "\n",
    "    # -------------------------\n",
    "    # Save the trained model\n",
    "    # -------------------------\n",
    "    torch.save(model.state_dict(), 'resnet18_imagenet.pth')\n",
    "    print(\"Model saved to resnet18_imagenet.pth\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
